{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from numpy import loadtxt, savetxt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import scikitplot\n",
    "from scikitplot.metrics import plot_roc_curve\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score,cross_validate, train_test_split, GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age  Brush  Ball  Watch  Mobile  Duster\n",
      "0    2   3.00  2.02   1.40    3.02    1.78\n",
      "1    2   2.61  2.51   5.57    2.26    2.34\n",
      "2    2  10.56  4.42  12.62    8.69   18.76\n",
      "3    2   3.05  2.89   3.13    3.49    3.22\n",
      "4    2   3.12  3.82   2.74    1.73    1.41\n",
      "[[  0. 112.]\n",
      " [  1.  37.]]\n",
      "[0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.\n",
      " 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "y = np.loadtxt(\"kmeanpredict.csv\", delimiter=\",\")\n",
    "dataset = pd.read_csv(r'C:\\Users\\rishi\\Desktop\\FinalDataset.csv')\n",
    "data = dataset.copy()\n",
    "data = pd.DataFrame(data)\n",
    "print(data.head())\n",
    "data.columns = ['Age', 'Brush', 'Ball', 'Watch', 'Mobile', 'Duster']\n",
    "X = data[['Age', 'Brush', 'Ball', 'Watch', 'Mobile', 'Duster']].to_numpy()\n",
    "(unique, counts) = np.unique(y, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(frequencies)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0. 82.]\n",
      " [ 1. 29.]]\n",
      "[[ 0. 30.]\n",
      " [ 1.  8.]]\n",
      "Fitting 9 folds for each of 1 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='logistic', alpha=0.1, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=10, learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "              validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "MLPClassifier(activation='logistic', alpha=0.1, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=10, learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "              validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "[0.98198198]\n",
      "98.1981981981982\n",
      "[30  0  1  7]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0    0.96774   1.00000   0.98361        30\n",
      "         1.0    1.00000   0.87500   0.93333         8\n",
      "\n",
      "    accuracy                        0.97368        38\n",
      "   macro avg    0.98387   0.93750   0.95847        38\n",
      "weighted avg    0.97453   0.97368   0.97302        38\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed:    2.8s remaining:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    2.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    2.8s finished\n",
      "C:\\Users\\rishi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "total = np.empty(0,dtype = float)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.25)\n",
    "(unique, counts) = np.unique(y_train, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "(unique, counts) = np.unique(y_test, return_counts=True)\n",
    "frequencies2 = np.asarray((unique, counts)).T\n",
    "print(frequencies)\n",
    "print(frequencies2)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "parameters = {'solver': ['lbfgs'], 'activation': ['logistic'], 'max_iter': [100], 'alpha': [0.1], 'hidden_layer_sizes':(10,)}\n",
    "clf = GridSearchCV(MLPClassifier(), parameters, n_jobs=-1, refit = True, verbose=2, cv=9)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_estimator_)\n",
    "total = np.append(total,clf.best_score_)\n",
    "print(clf.best_estimator_)\n",
    "print(total)\n",
    "print(np.mean(total)*100)\n",
    "clf_predictions = clf.predict(X_test)\n",
    "#grid_prob = grid.predict_proba(X_test)\n",
    "print(confusion_matrix(y_test,clf_predictions).ravel())\n",
    "print(classification_report(y_test,clf_predictions,digits = 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9736842105263158\n",
      "[0.94444444 1.         1.         1.         0.9375     1.\n",
      " 1.         1.         1.        ]\n",
      "98.68827160493827\n"
     ]
    }
   ],
   "source": [
    "clf1 = MLPClassifier(activation='logistic', alpha=0.1, batch_size='auto', beta_1=0.9,\n",
    "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "              hidden_layer_sizes=10, learning_rate='constant',\n",
    "              learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
    "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
    "              random_state=None, shuffle=True, solver='lbfgs', tol=0.0001,\n",
    "              validation_fraction=0.1, verbose=False, warm_start=False)\n",
    "clf1.fit(X_train, y_train)\n",
    "y_pred = clf1.predict(X_test)\n",
    "print(clf1.score(X_test,y_test))\n",
    "scaler = preprocessing.StandardScaler()\n",
    "data_scaled = scaler.fit_transform(X)\n",
    "scores = cross_val_score(clf1, data_scaled, y, cv=9)\n",
    "print(scores)\n",
    "final = np.mean(scores)\n",
    "print(final*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# total = np.empty(0,dtype = float)\n",
    "# for i in range(0,10):\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.25,random_state = i)\n",
    "#     (unique, counts) = np.unique(y_train, return_counts=True)\n",
    "#     frequencies = np.asarray((unique, counts)).T\n",
    "#     (unique, counts) = np.unique(y_test, return_counts=True)\n",
    "#     frequencies2 = np.asarray((unique, counts)).T\n",
    "#     print(frequencies)\n",
    "#     print(frequencies2)\n",
    "#     scaler = preprocessing.StandardScaler()\n",
    "#     X_train = scaler.fit_transform(X_train)\n",
    "#     X_test = scaler.transform(X_test)\n",
    "#     parameters = {'solver': ['sgd'],'batch_size': [27], 'learning_rate_init': 10.0 ** -np.arange(1, 5),'activation': ['identity'], 'max_iter': [50,100,200,300,400,500], 'alpha': 10.0 ** -np.arange(1, 6), 'hidden_layer_sizes':(10,)}\n",
    "#     clf = GridSearchCV(MLPClassifier(), parameters, n_jobs=-1,refit = True, verbose=2, cv = 4)\n",
    "#     clf.fit(X_train, y_train)\n",
    "#     print(clf.best_estimator_)\n",
    "#     total = np.append(total,clf.best_score_)\n",
    "\n",
    "# print(total)\n",
    "# print(np.mean(total)*100)\n",
    "# clf_predictions = clf.predict(X_test)\n",
    "# #grid_prob = grid.predict_proba(X_test)\n",
    "# print(confusion_matrix(y_test,clf_predictions).ravel())\n",
    "# print(classification_report(y_test,clf_predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = MLPClassifier(activation='tanh', alpha=0.01, batch_size=27, beta_1=0.9,\n",
    "#               beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "#               hidden_layer_sizes=10, learning_rate='constant',\n",
    "#               learning_rate_init=0.1, max_iter=100, momentum=0.9,\n",
    "#               n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
    "#               shuffle=True, solver='sgd', tol=0.0001, random_state = 3,\n",
    "#               validation_fraction=0.1, verbose=False, warm_start=False)\n",
    "# for i in range(3,11):\n",
    "#     scores = cross_val_score(clf, X, y, n_jobs = -1, verbose = True, cv = i)\n",
    "#     print(scores)\n",
    "#     final = np.mean(scores)\n",
    "#     print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
