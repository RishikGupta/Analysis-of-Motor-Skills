{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed\n",
    "from random import randrange\n",
    "from csv import reader\n",
    "from math import exp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "from numpy import loadtxt, savetxt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = list()\n",
    "finalmean = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [93.75, 93.75, 100.0, 100.0, 93.75, 100.0, 81.25, 100.0, 93.75]\n",
      "Mean Accuracy: 95.139%\n",
      "[106   2   5  31]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.97       108\n",
      "         1.0       0.94      0.86      0.90        36\n",
      "\n",
      "    accuracy                           0.95       144\n",
      "   macro avg       0.95      0.92      0.93       144\n",
      "weighted avg       0.95      0.95      0.95       144\n",
      "\n",
      "0.04861111111111111\n",
      "Scores: [100.0, 93.75, 100.0, 93.75, 100.0, 100.0, 87.5, 93.75, 100.0]\n",
      "Mean Accuracy: 96.528%\n",
      "[109   0   5  30]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98       109\n",
      "         1.0       1.00      0.86      0.92        35\n",
      "\n",
      "    accuracy                           0.97       144\n",
      "   macro avg       0.98      0.93      0.95       144\n",
      "weighted avg       0.97      0.97      0.96       144\n",
      "\n",
      "0.034722222222222224\n",
      "Scores: [93.75, 100.0, 81.25, 93.75, 100.0, 100.0, 100.0, 100.0, 100.0]\n",
      "Mean Accuracy: 96.528%\n",
      "[108   0   5  31]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98       108\n",
      "         1.0       1.00      0.86      0.93        36\n",
      "\n",
      "    accuracy                           0.97       144\n",
      "   macro avg       0.98      0.93      0.95       144\n",
      "weighted avg       0.97      0.97      0.96       144\n",
      "\n",
      "0.034722222222222224\n",
      "Scores: [100.0, 100.0, 87.5, 93.75, 100.0, 100.0, 100.0, 100.0, 100.0]\n",
      "Mean Accuracy: 97.917%\n",
      "[109   0   3  32]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.99       109\n",
      "         1.0       1.00      0.91      0.96        35\n",
      "\n",
      "    accuracy                           0.98       144\n",
      "   macro avg       0.99      0.96      0.97       144\n",
      "weighted avg       0.98      0.98      0.98       144\n",
      "\n",
      "0.020833333333333332\n",
      "Scores: [93.75, 100.0, 100.0, 93.75, 93.75, 100.0, 81.25, 93.75, 100.0]\n",
      "Mean Accuracy: 95.139%\n",
      "[107   1   6  30]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97       108\n",
      "         1.0       0.97      0.83      0.90        36\n",
      "\n",
      "    accuracy                           0.95       144\n",
      "   macro avg       0.96      0.91      0.93       144\n",
      "weighted avg       0.95      0.95      0.95       144\n",
      "\n",
      "0.04861111111111111\n",
      "Scores: [93.75, 93.75, 100.0, 87.5, 100.0, 100.0, 93.75, 93.75, 100.0]\n",
      "Mean Accuracy: 95.833%\n",
      "[108   0   6  30]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      1.00      0.97       108\n",
      "         1.0       1.00      0.83      0.91        36\n",
      "\n",
      "    accuracy                           0.96       144\n",
      "   macro avg       0.97      0.92      0.94       144\n",
      "weighted avg       0.96      0.96      0.96       144\n",
      "\n",
      "0.041666666666666664\n",
      "Scores: [100.0, 93.75, 100.0, 100.0, 100.0, 100.0, 93.75, 100.0, 87.5]\n",
      "Mean Accuracy: 97.222%\n",
      "[108   0   4  32]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98       108\n",
      "         1.0       1.00      0.89      0.94        36\n",
      "\n",
      "    accuracy                           0.97       144\n",
      "   macro avg       0.98      0.94      0.96       144\n",
      "weighted avg       0.97      0.97      0.97       144\n",
      "\n",
      "0.027777777777777776\n",
      "Scores: [100.0, 93.75, 100.0, 93.75, 100.0, 100.0, 93.75, 93.75, 100.0]\n",
      "Mean Accuracy: 97.222%\n",
      "[108   0   4  32]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98       108\n",
      "         1.0       1.00      0.89      0.94        36\n",
      "\n",
      "    accuracy                           0.97       144\n",
      "   macro avg       0.98      0.94      0.96       144\n",
      "weighted avg       0.97      0.97      0.97       144\n",
      "\n",
      "0.027777777777777776\n",
      "Scores: [100.0, 87.5, 87.5, 100.0, 100.0, 100.0, 100.0, 87.5, 93.75]\n",
      "Mean Accuracy: 95.139%\n",
      "[107   0   7  30]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      1.00      0.97       107\n",
      "         1.0       1.00      0.81      0.90        37\n",
      "\n",
      "    accuracy                           0.95       144\n",
      "   macro avg       0.97      0.91      0.93       144\n",
      "weighted avg       0.95      0.95      0.95       144\n",
      "\n",
      "0.04861111111111111\n",
      "Scores: [100.0, 100.0, 93.75, 87.5, 100.0, 100.0, 93.75, 100.0, 100.0]\n",
      "Mean Accuracy: 97.222%\n",
      "[110   0   4  30]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98       110\n",
      "         1.0       1.00      0.88      0.94        34\n",
      "\n",
      "    accuracy                           0.97       144\n",
      "   macro avg       0.98      0.94      0.96       144\n",
      "weighted avg       0.97      0.97      0.97       144\n",
      "\n",
      "0.027777777777777776\n",
      "Scores: [100.0, 100.0, 100.0, 100.0, 87.5, 100.0, 87.5, 100.0, 93.75]\n",
      "Mean Accuracy: 96.528%\n",
      "[109   1   4  30]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.99      0.98       110\n",
      "         1.0       0.97      0.88      0.92        34\n",
      "\n",
      "    accuracy                           0.97       144\n",
      "   macro avg       0.97      0.94      0.95       144\n",
      "weighted avg       0.97      0.97      0.96       144\n",
      "\n",
      "0.034722222222222224\n",
      "Scores: [93.75, 100.0, 100.0, 100.0, 100.0, 87.5, 100.0, 87.5, 100.0]\n",
      "Mean Accuracy: 96.528%\n",
      "[108   0   5  31]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98       108\n",
      "         1.0       1.00      0.86      0.93        36\n",
      "\n",
      "    accuracy                           0.97       144\n",
      "   macro avg       0.98      0.93      0.95       144\n",
      "weighted avg       0.97      0.97      0.96       144\n",
      "\n",
      "0.034722222222222224\n",
      "Scores: [93.75, 100.0, 100.0, 93.75, 93.75, 93.75, 93.75, 100.0, 87.5]\n",
      "Mean Accuracy: 95.139%\n",
      "[105   2   5  32]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.97       107\n",
      "         1.0       0.94      0.86      0.90        37\n",
      "\n",
      "    accuracy                           0.95       144\n",
      "   macro avg       0.95      0.92      0.93       144\n",
      "weighted avg       0.95      0.95      0.95       144\n",
      "\n",
      "0.04861111111111111\n",
      "Scores: [100.0, 100.0, 93.75, 93.75, 100.0, 100.0, 87.5, 100.0, 75.0]\n",
      "Mean Accuracy: 94.444%\n",
      "[107   1   7  29]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.99      0.96       108\n",
      "         1.0       0.97      0.81      0.88        36\n",
      "\n",
      "    accuracy                           0.94       144\n",
      "   macro avg       0.95      0.90      0.92       144\n",
      "weighted avg       0.95      0.94      0.94       144\n",
      "\n",
      "0.05555555555555555\n",
      "Scores: [93.75, 93.75, 100.0, 100.0, 93.75, 93.75, 100.0, 100.0, 93.75]\n",
      "Mean Accuracy: 96.528%\n",
      "[109   0   5  30]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98       109\n",
      "         1.0       1.00      0.86      0.92        35\n",
      "\n",
      "    accuracy                           0.97       144\n",
      "   macro avg       0.98      0.93      0.95       144\n",
      "weighted avg       0.97      0.97      0.96       144\n",
      "\n",
      "0.034722222222222224\n",
      "Scores: [93.75, 100.0, 100.0, 100.0, 100.0, 81.25, 100.0, 93.75, 100.0]\n",
      "Mean Accuracy: 96.528%\n",
      "[106   2   3  33]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.98      0.98       108\n",
      "         1.0       0.94      0.92      0.93        36\n",
      "\n",
      "    accuracy                           0.97       144\n",
      "   macro avg       0.96      0.95      0.95       144\n",
      "weighted avg       0.97      0.97      0.97       144\n",
      "\n",
      "0.034722222222222224\n",
      "Scores: [100.0, 93.75, 93.75, 100.0, 100.0, 100.0, 100.0, 100.0, 87.5]\n",
      "Mean Accuracy: 97.222%\n",
      "[110   1   3  30]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.99      0.98       111\n",
      "         1.0       0.97      0.91      0.94        33\n",
      "\n",
      "    accuracy                           0.97       144\n",
      "   macro avg       0.97      0.95      0.96       144\n",
      "weighted avg       0.97      0.97      0.97       144\n",
      "\n",
      "0.027777777777777776\n",
      "Scores: [100.0, 93.75, 100.0, 100.0, 87.5, 100.0, 100.0, 93.75, 87.5]\n",
      "Mean Accuracy: 95.833%\n",
      "[107   1   5  31]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.99      0.97       108\n",
      "         1.0       0.97      0.86      0.91        36\n",
      "\n",
      "    accuracy                           0.96       144\n",
      "   macro avg       0.96      0.93      0.94       144\n",
      "weighted avg       0.96      0.96      0.96       144\n",
      "\n",
      "0.041666666666666664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [100.0, 100.0, 100.0, 100.0, 93.75, 93.75, 100.0, 93.75, 93.75]\n",
      "Mean Accuracy: 97.222%\n",
      "[109   0   4  31]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98       109\n",
      "         1.0       1.00      0.89      0.94        35\n",
      "\n",
      "    accuracy                           0.97       144\n",
      "   macro avg       0.98      0.94      0.96       144\n",
      "weighted avg       0.97      0.97      0.97       144\n",
      "\n",
      "0.027777777777777776\n",
      "Scores: [87.5, 100.0, 93.75, 87.5, 93.75, 100.0, 100.0, 100.0, 100.0]\n",
      "Mean Accuracy: 95.833%\n",
      "[108   0   6  30]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      1.00      0.97       108\n",
      "         1.0       1.00      0.83      0.91        36\n",
      "\n",
      "    accuracy                           0.96       144\n",
      "   macro avg       0.97      0.92      0.94       144\n",
      "weighted avg       0.96      0.96      0.96       144\n",
      "\n",
      "0.041666666666666664\n",
      "96.28472222222221\n",
      "0.03715277777777777\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression on MOTOR SKILLS\n",
    "\n",
    "# Load a CSV file\n",
    "def load_csv(filename):\n",
    "\tdataset = list()\n",
    "\twith open(filename, 'r') as file:\n",
    "\t\tcsv_reader = reader(file)\n",
    "\t\tfor row in csv_reader:\n",
    "\t\t\tif not row:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tdataset.append(row)\n",
    "\treturn dataset\n",
    "\n",
    "# Convert string column to float\n",
    "def str_column_to_float(dataset, column):\n",
    "\tfor row in dataset:\n",
    "\t\trow[column] = float(row[column].strip())\n",
    "\n",
    "# Find the min and max values for each column\n",
    "def dataset_minmax(dataset):\n",
    "\tminmax = list()\n",
    "\tfor i in range(len(dataset[0])):\n",
    "\t\tcol_values = [row[i] for row in dataset]\n",
    "\t\tvalue_min = min(col_values)\n",
    "\t\tvalue_max = max(col_values)\n",
    "\t\tminmax.append([value_min, value_max])\n",
    "\treturn minmax\n",
    "\n",
    "# Rescale dataset columns to the range 0-1\n",
    "def normalize_dataset(dataset, minmax):\n",
    "\tfor row in dataset:\n",
    "\t\tfor i in range(len(row)):\n",
    "\t\t\trow[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n",
    "\n",
    "# Split a dataset into k folds\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "\tdataset_split = list()\n",
    "\tdataset_copy = list(dataset)\n",
    "\tfold_size = int(len(dataset) / n_folds)\n",
    "\tfor i in range(n_folds):\n",
    "\t\tfold = list()\n",
    "\t\twhile len(fold) < fold_size:\n",
    "\t\t\tindex = randrange(len(dataset_copy))\n",
    "\t\t\tfold.append(dataset_copy.pop(index))\n",
    "\t\tdataset_split.append(fold)\n",
    "\treturn dataset_split\n",
    "\n",
    "# Calculate accuracy percentage\n",
    "def accuracy_metric(actual, predicted):\n",
    "\t#print(confusion_matrix(actual,predicted).ravel())\n",
    "\t#print(classification_report(actual,predicted)) \n",
    "\tcorrect = 0\n",
    "\tfor i in range(len(actual)):\n",
    "\t\tif actual[i] == predicted[i]:\n",
    "\t\t\tcorrect += 1\n",
    "\treturn correct / float(len(actual)) * 100.0\n",
    "\n",
    "# Evaluate an algorithm using a cross validation split\n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "\tfolds = cross_validation_split(dataset, n_folds)\n",
    "\tscores = list()\n",
    "\tfinal_pred = list()\n",
    "\tfinal_actu = list()\n",
    "\tfor fold in folds:\n",
    "\t\ttrain_set = list(folds)\n",
    "\t\ttrain_set.remove(fold)\n",
    "\t\ttrain_set = sum(train_set, [])\n",
    "\t\ttest_set = list()\n",
    "\t\tfor row in fold:\n",
    "\t\t\trow_copy = list(row)\n",
    "\t\t\ttest_set.append(row_copy)\n",
    "\t\t\trow_copy[-1] = None\n",
    "\t\tpredicted = algorithm(train_set, test_set, *args)\n",
    "\t\tactual = [row[-1] for row in fold]\n",
    "\t\tfinal_pred += predicted\n",
    "\t\tfinal_actu += actual        \n",
    "\t\taccuracy = accuracy_metric(actual, predicted)\n",
    "\t\tscores.append(accuracy)\n",
    "\treturn scores, final_pred, final_actu\n",
    "\n",
    "# Make a prediction with coefficients\n",
    "def predict(row, coefficients):\n",
    "\tyhat = coefficients[0]\n",
    "\tfor i in range(len(row)-1):\n",
    "\t\tyhat += coefficients[i + 1] * row[i]\n",
    "\treturn 1.0 / (1.0 + exp(-yhat))\n",
    "\n",
    "# Estimate logistic regression coefficients using stochastic gradient descent\n",
    "def coefficients_sgd(train, l_rate, n_epoch):\n",
    "\tcoef = [0.0 for i in range(len(train[0]))]\n",
    "\tfor epoch in range(n_epoch):\n",
    "\t\tfor row in train:\n",
    "\t\t\tyhat = predict(row, coef)\n",
    "\t\t\terror = row[-1] - yhat\n",
    "\t\t\tcoef[0] = coef[0] + l_rate * error * yhat * (1.0 - yhat)\n",
    "\t\t\tfor i in range(len(row)-1):\n",
    "\t\t\t\tcoef[i + 1] = coef[i + 1] + l_rate * error * yhat * (1.0 - yhat) * row[i]\n",
    "\treturn coef\n",
    "\n",
    "# Linear Regression Algorithm With Stochastic Gradient Descent\n",
    "def logistic_regression(train, test, l_rate, n_epoch):\n",
    "\tpredictions = list()\n",
    "\tcoef = coefficients_sgd(train, l_rate, n_epoch)\n",
    "\tfor row in test:\n",
    "\t\tyhat = predict(row, coef)\n",
    "\t\tyhat = round(yhat)\n",
    "\t\tpredictions.append(yhat)\n",
    "\treturn(predictions)\n",
    "\n",
    "# Test the logistic regression algorithm on the diabetes dataset\n",
    "#seed(1)\n",
    "# load and prepare data\n",
    "filename = r'C:\\Users\\rishi\\Desktop\\Logdata.csv'\n",
    "dataset = load_csv(filename)\n",
    "for i in range(len(dataset[0])):\n",
    "\tstr_column_to_float(dataset, i)\n",
    "# normalize\n",
    "minmax = dataset_minmax(dataset)\n",
    "normalize_dataset(dataset, minmax)\n",
    "# evaluate algorithm\n",
    "for checknum in range(1,21):\n",
    "    n_folds = 9\n",
    "    l_rate = 0.6\n",
    "    n_epoch = 300\n",
    "    scores, final_predicted, final_actual = evaluate_algorithm(dataset, logistic_regression, n_folds, l_rate, n_epoch)\n",
    "    print('Scores: %s' % scores)\n",
    "    mean_acc = sum(scores)/float(len(scores))\n",
    "    final.append(mean_acc)\n",
    "    finalmean.append(mean_squared_error(final_actual, final_predicted))\n",
    "    print('Mean Accuracy: %.3f%%' % (mean_acc))\n",
    "    print(confusion_matrix(final_actual,final_predicted).ravel())\n",
    "    print(classification_report(final_actual,final_predicted))\n",
    "    print(mean_squared_error(final_actual, final_predicted))\n",
    "print(np.mean(final))\n",
    "print(np.mean(finalmean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from numpy import loadtxt, savetxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = np.loadtxt(\"kmeanpredict.csv\", delimiter=\",\")\n",
    "# dataset = pd.read_csv(r'C:\\Users\\rishi\\Desktop\\FinalDataset.csv')\n",
    "# data = dataset.copy()\n",
    "# data = pd.DataFrame(data)\n",
    "# data.columns = ['Age', 'Brush', 'Ball', 'Watch', 'Mobile', 'Duster']\n",
    "# X = data[['Age', 'Brush', 'Ball', 'Watch', 'Mobile', 'Duster']].to_numpy()\n",
    "# print(y)\n",
    "# LRG = LogisticRegression(max_iter = 300, random_state = 0,solver = 'liblinear',multi_class = 'auto').fit(X, y)\n",
    "# print(LRG.score(X, y))\n",
    "# LRG.densify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
